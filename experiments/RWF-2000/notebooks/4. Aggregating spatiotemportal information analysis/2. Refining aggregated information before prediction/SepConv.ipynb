{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "* Openpose (+gamma) without background and frame difference as input. Addition as combination\n",
    "\n",
    "* preConvLSTM of 9 filters\n",
    "\n",
    "* ConvLSTM of 32 filters\n",
    "\n",
    "* SepConv of 64 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:25.977498Z",
     "iopub.status.busy": "2022-03-11T13:19:25.977059Z",
     "iopub.status.idle": "2022-03-11T13:19:25.981746Z",
     "shell.execute_reply": "2022-03-11T13:19:25.980719Z",
     "shell.execute_reply.started": "2022-03-11T13:19:25.977465Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use output of OpenPose with or without background\n",
    "BACKGROUND = False\n",
    "# Paths to videos for training\n",
    "PATHS = [\"../../../datasets/RWF-2000\", f\"../../../datasets/openpose_processed/gamma/{'' if BACKGROUND else 'no_'}back\"]\n",
    "\n",
    "FRAME_FUNC = 'frame_diff'\n",
    "# To use frame diff to weight t (current) or t+1\n",
    "WEIGHT_CURRENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:25.98401Z",
     "iopub.status.busy": "2022-03-11T13:19:25.983753Z",
     "iopub.status.idle": "2022-03-11T13:19:25.991894Z",
     "shell.execute_reply": "2022-03-11T13:19:25.991105Z",
     "shell.execute_reply.started": "2022-03-11T13:19:25.983972Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 11:49:54.113900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.114575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.115436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.121105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.121795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.122652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.123079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.123714: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.124550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "!export TF_FORCE_GPU_ALLOW_GROWTH=True\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[1:], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:25.99373Z",
     "iopub.status.busy": "2022-03-11T13:19:25.993435Z",
     "iopub.status.idle": "2022-03-11T13:19:26.016866Z",
     "shell.execute_reply": "2022-03-11T13:19:26.016121Z",
     "shell.execute_reply.started": "2022-03-11T13:19:25.993694Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.020522Z",
     "iopub.status.busy": "2022-03-11T13:19:26.019963Z",
     "iopub.status.idle": "2022-03-11T13:19:26.026099Z",
     "shell.execute_reply": "2022-03-11T13:19:26.025371Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.020483Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.029742Z",
     "iopub.status.busy": "2022-03-11T13:19:26.029354Z",
     "iopub.status.idle": "2022-03-11T13:19:26.044202Z",
     "shell.execute_reply": "2022-03-11T13:19:26.042228Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.029704Z"
    }
   },
   "outputs": [],
   "source": [
    "ORIGINAL_FRAMES_PER_VIDEO = 150\n",
    "FRAMES_PER_VIDEO = 50 + 1\n",
    "VIDEO_WIDTH, VIDEO_HEIGHT = 100, 100\n",
    "N_CHANNELS = 3\n",
    "\n",
    "def load_videos(video_IDs: list, video_frames: int = FRAMES_PER_VIDEO, video_width: int = VIDEO_WIDTH, video_height: int = VIDEO_HEIGHT,\n",
    "                video_channels: int = N_CHANNELS, dtype = np.float32, normalize: bool = False) -> tuple:\n",
    "    videos = np.empty((len(video_IDs), video_frames, video_height, video_width, video_channels), dtype=dtype)\n",
    "\n",
    "    # Indexes of frames to be kept to comply with video_frames\n",
    "    frames_idx = set(np.round(np.linspace(0, ORIGINAL_FRAMES_PER_VIDEO - 1, video_frames)).astype(int))\n",
    "\n",
    "    for i, video_ID in enumerate(video_IDs):\n",
    "        cap = cv2.VideoCapture(video_ID)\n",
    "        frames = []\n",
    "        index = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if index in frames_idx:\n",
    "                frame = cv2.resize(frame, (video_width, video_height)).astype(dtype)\n",
    "                if normalize:\n",
    "                    frame /= 255.0\n",
    "                frames.append(frame)\n",
    "            index += 1\n",
    "        cap.release()\n",
    "\n",
    "        videos[i,] = np.array(frames)\n",
    "\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataGenerator class to load videos per batch, in case all videos do not fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.045807Z",
     "iopub.status.busy": "2022-03-11T13:19:26.045605Z",
     "iopub.status.idle": "2022-03-11T13:19:26.059732Z",
     "shell.execute_reply": "2022-03-11T13:19:26.058897Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.045781Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, video_IDs: list, video_labels: dict, batch_size: int, paths: list = [''], video_width: int = VIDEO_WIDTH, video_height: int = VIDEO_HEIGHT,\n",
    "                video_frames: int = FRAMES_PER_VIDEO, video_channels: int = N_CHANNELS, dtype = np.float32, normalize: bool = False, shuffle: bool = True):\n",
    "        self.video_IDs = video_IDs\n",
    "        self.video_labels = video_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.paths = paths\n",
    "        self.video_width = video_width\n",
    "        self.video_height = video_height\n",
    "        self.video_frames = video_frames\n",
    "        self.video_channels = video_channels\n",
    "        self.dtype = dtype\n",
    "        self.normalize = normalize\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_IDs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_IDs = self.video_IDs[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        input_videos = []\n",
    "        \n",
    "        for index, path in enumerate(self.paths):\n",
    "            batch_IDs_full_path = [path+ID for ID in batch_IDs]\n",
    "\n",
    "            videos = load_videos(batch_IDs_full_path, self.video_frames, self.video_width, \n",
    "                                         self.video_height, self.video_channels, self.dtype, self.normalize)\n",
    "            \n",
    "            input_videos.append(videos)\n",
    "        \n",
    "        labels = np.array([self.video_labels[ID] for ID in batch_IDs])\n",
    "                    \n",
    "        return input_videos, labels\n",
    "            \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.video_IDs)\n",
    "        # Clear memory after epochs\n",
    "        gc.collect()\n",
    "        #K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slug_from_path(path):\n",
    "    \"\"\"\n",
    "    Function to get slug from path\n",
    "    slug must contain /train or /val because there are repeated names\n",
    "    \"\"\"\n",
    "    # Try train index first\n",
    "    index = path.rfind('/train/')\n",
    "    if index == -1:\n",
    "        index = path.rfind('/val/')\n",
    "    return path[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.062131Z",
     "iopub.status.busy": "2022-03-11T13:19:26.06193Z",
     "iopub.status.idle": "2022-03-11T13:19:26.085657Z",
     "shell.execute_reply": "2022-03-11T13:19:26.084932Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.062105Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_video_IDs = [get_slug_from_path(path) for path in glob.glob(PATHS[0]+'/train/*/*')]\n",
    "test_video_IDs = [get_slug_from_path(path) for path in glob.glob(PATHS[0]+'/val/*/*')]\n",
    "\n",
    "train_video_labels = {video: 0 if 'NonFight' in video else 1 for video in train_video_IDs}\n",
    "test_video_labels = {video: 0 if 'NonFight' in video else 1 for video in test_video_IDs}\n",
    "\n",
    "\n",
    "train_generator = DataGenerator(train_video_IDs, train_video_labels, batch_size=10, paths=PATHS)\n",
    "test_generator = DataGenerator(test_video_IDs, test_video_labels, batch_size=10, paths=PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def tf_frame_diff(video):\n",
    "    return video[1:] - video[:-1]\n",
    "\n",
    "def tf_frame_dist(video):\n",
    "    video_diff = tf_frame_diff(video)\n",
    "    return K.sqrt(K.sum(K.square(video_diff), axis=-1, keepdims=True))\n",
    "\n",
    "if WEIGHT_CURRENT:\n",
    "    def tf_frame_diff_dist_combined(video):\n",
    "        video_diff = tf_frame_diff(video)\n",
    "        video_diff_current = tf.nn.relu(-video_diff)\n",
    "        video_diff_next = tf.nn.relu(video_diff)\n",
    "        video_diff_next_norm = K.sqrt(K.sum(K.square(video_diff_next), axis=-1, keepdims=True))\n",
    "        return K.concatenate([video_diff_current, video_diff_next_norm])\n",
    "else:\n",
    "    def tf_frame_diff_dist_combined(video):\n",
    "        video_diff = tf_frame_diff(video)\n",
    "        video_diff_current = tf.nn.relu(video_diff)\n",
    "        video_diff_prev = tf.nn.relu(-video_diff)\n",
    "        video_diff_prev_norm = K.sqrt(K.sum(K.square(video_diff_prev), axis=-1, keepdims=True))\n",
    "        return K.concatenate([video_diff_current, video_diff_prev_norm])\n",
    "    \n",
    "frame_func_dict = {'frame_diff': tf_frame_diff, 'frame_dist': tf_frame_dist, 'frame_diff_dist_combined': tf_frame_diff_dist_combined}\n",
    "frame_func = frame_func_dict[FRAME_FUNC]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.087766Z",
     "iopub.status.busy": "2022-03-11T13:19:26.087254Z",
     "iopub.status.idle": "2022-03-11T13:19:26.223842Z",
     "shell.execute_reply": "2022-03-11T13:19:26.223066Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.087727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 51, 100, 10  0           []                               \n",
      "                                0, 3)]                                                            \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 51, 100, 10  0           []                               \n",
      "                                0, 3)]                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 50, 100, 100  0          ['input_2[0][0]']                \n",
      " ingOpLambda)                   , 3)                                                              \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 50, 100, 100  0           ['input_1[0][0]']                \n",
      "                                , 3)                                                              \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 50, 98, 98,   252        ['tf.__operators__.getitem[0][0]'\n",
      " ted)                           9)                               ]                                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 50, 100, 100  12         ['lambda[0][0]']                 \n",
      " alization)                     , 3)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 50, 98, 98,   18         ['time_distributed[0][0]']       \n",
      " rmalization)                   9)                                                                \n",
      "                                                                                                  \n",
      " conv_lstm2d (ConvLSTM2D)       (None, 50, 98, 98,   3924        ['batch_normalization[0][0]']    \n",
      "                                9)                                                                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 50, 98, 98,   0           ['batch_normalization_1[0][0]',  \n",
      "                                9)                                'conv_lstm2d[0][0]']            \n",
      "                                                                                                  \n",
      " conv_lstm2d_1 (ConvLSTM2D)     (None, 96, 96, 32)   47360       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " separable_conv2d (SeparableCon  (None, 94, 94, 64)  2400        ['conv_lstm2d_1[0][0]']          \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['separable_conv2d[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          8320        ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           2064        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            17          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 64,367\n",
      "Trainable params: 64,343\n",
      "Non-trainable params: 24\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 11:49:54.219518: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 11:49:54.382782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.383630: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.384029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.384817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.385195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:54.385983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.084532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.085424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.085832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.086648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.087048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.087859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16383 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:61:00.0, compute capability: 8.0\n",
      "2022-05-06 11:49:55.088178: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 11:49:55.088559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 1681 MB memory:  -> device: 2, name: NVIDIA T1000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "inputs_raw = tf.keras.layers.Input(shape=(FRAMES_PER_VIDEO, VIDEO_HEIGHT, VIDEO_WIDTH, N_CHANNELS))\n",
    "inputs_openpose = tf.keras.layers.Input(shape=(FRAMES_PER_VIDEO, VIDEO_HEIGHT, VIDEO_WIDTH, N_CHANNELS))\n",
    "\n",
    "inputs_diff = tf.keras.layers.Lambda(lambda video: tf.map_fn(frame_func, video))(inputs_raw)\n",
    "inputs_to_weight = inputs_openpose[:, :-1] if WEIGHT_CURRENT else inputs_openpose[:, 1:]\n",
    "\n",
    "inputs_diff_norm = tf.keras.layers.BatchNormalization()(inputs_diff)\n",
    "inputs_diff_time_info_weight = tf.keras.layers.ConvLSTM2D(filters=9, kernel_size=(3, 3), return_sequences=True, data_format='channels_last', activation='tanh')(inputs_diff_norm)\n",
    "\n",
    "convolutional_layer = tf.keras.layers.Conv2D(filters=9, kernel_size=(3,3), activation='relu')\n",
    "inputs_openpose_soft = tf.keras.layers.TimeDistributed(convolutional_layer)(inputs_to_weight)\n",
    "\n",
    "inputs_openpose_norm = tf.keras.layers.BatchNormalization(scale=False, center=False)(inputs_openpose_soft)\n",
    "\n",
    "inputs_weighted = tf.keras.layers.Add()([inputs_openpose_norm, inputs_diff_time_info_weight])\n",
    "\n",
    "x = tf.keras.layers.ConvLSTM2D(filters=32, kernel_size=(3, 3), return_sequences=False, data_format='channels_last', activation='tanh')(inputs_weighted)\n",
    "\n",
    "x = tf.keras.layers.SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', data_format='channels_last')(x)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D(data_format='channels_last')(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=16, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.Model([inputs_raw, inputs_openpose], outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.225669Z",
     "iopub.status.busy": "2022-03-11T13:19:26.225387Z",
     "iopub.status.idle": "2022-03-11T14:02:30.18049Z",
     "shell.execute_reply": "2022-03-11T14:02:30.177368Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.225631Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 11:50:04.434898: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8303\n",
      "2022-05-06 11:50:05.229121: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-05-06 11:50:05.230940: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2022-05-06 11:50:05.230971: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-05-06 11:50:05.231096: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-05-06 11:50:05.643638: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 - 522s - loss: 0.6914 - accuracy: 0.5069 - val_loss: 0.6609 - val_accuracy: 0.6750 - 522s/epoch - 3s/step\n",
      "Epoch 2/30\n",
      "160/160 - 515s - loss: 0.5870 - accuracy: 0.7094 - val_loss: 0.4811 - val_accuracy: 0.7700 - 515s/epoch - 3s/step\n",
      "Epoch 3/30\n",
      "160/160 - 520s - loss: 0.4925 - accuracy: 0.7694 - val_loss: 0.4543 - val_accuracy: 0.8000 - 520s/epoch - 3s/step\n",
      "Epoch 4/30\n",
      "160/160 - 514s - loss: 0.4360 - accuracy: 0.8037 - val_loss: 0.3566 - val_accuracy: 0.8600 - 514s/epoch - 3s/step\n",
      "Epoch 5/30\n",
      "160/160 - 517s - loss: 0.4195 - accuracy: 0.8156 - val_loss: 0.3417 - val_accuracy: 0.8575 - 517s/epoch - 3s/step\n",
      "Epoch 6/30\n",
      "160/160 - 520s - loss: 0.3827 - accuracy: 0.8400 - val_loss: 0.3744 - val_accuracy: 0.8450 - 520s/epoch - 3s/step\n",
      "Epoch 7/30\n",
      "160/160 - 519s - loss: 0.3948 - accuracy: 0.8369 - val_loss: 0.3435 - val_accuracy: 0.8750 - 519s/epoch - 3s/step\n",
      "Epoch 8/30\n",
      "160/160 - 521s - loss: 0.3694 - accuracy: 0.8419 - val_loss: 0.3252 - val_accuracy: 0.8775 - 521s/epoch - 3s/step\n",
      "Epoch 9/30\n",
      "160/160 - 521s - loss: 0.3530 - accuracy: 0.8606 - val_loss: 0.3408 - val_accuracy: 0.8875 - 521s/epoch - 3s/step\n",
      "Epoch 10/30\n",
      "160/160 - 520s - loss: 0.3426 - accuracy: 0.8612 - val_loss: 0.3609 - val_accuracy: 0.8600 - 520s/epoch - 3s/step\n",
      "Epoch 11/30\n",
      "160/160 - 522s - loss: 0.3450 - accuracy: 0.8569 - val_loss: 0.3494 - val_accuracy: 0.8700 - 522s/epoch - 3s/step\n",
      "Epoch 12/30\n",
      "160/160 - 521s - loss: 0.3295 - accuracy: 0.8662 - val_loss: 0.3270 - val_accuracy: 0.8925 - 521s/epoch - 3s/step\n",
      "Epoch 13/30\n",
      "160/160 - 518s - loss: 0.3034 - accuracy: 0.8781 - val_loss: 0.3108 - val_accuracy: 0.8925 - 518s/epoch - 3s/step\n",
      "Epoch 14/30\n",
      "160/160 - 517s - loss: 0.3006 - accuracy: 0.8806 - val_loss: 0.3665 - val_accuracy: 0.8675 - 517s/epoch - 3s/step\n",
      "Epoch 15/30\n",
      "160/160 - 518s - loss: 0.2976 - accuracy: 0.8825 - val_loss: 0.3466 - val_accuracy: 0.8750 - 518s/epoch - 3s/step\n",
      "Epoch 16/30\n",
      "160/160 - 518s - loss: 0.2824 - accuracy: 0.8906 - val_loss: 0.3425 - val_accuracy: 0.8700 - 518s/epoch - 3s/step\n",
      "Epoch 17/30\n",
      "160/160 - 521s - loss: 0.2862 - accuracy: 0.8850 - val_loss: 0.3315 - val_accuracy: 0.8800 - 521s/epoch - 3s/step\n",
      "Epoch 18/30\n",
      "160/160 - 521s - loss: 0.2786 - accuracy: 0.8981 - val_loss: 0.3630 - val_accuracy: 0.8650 - 521s/epoch - 3s/step\n",
      "Epoch 20/30\n",
      "160/160 - 520s - loss: 0.2750 - accuracy: 0.8950 - val_loss: 0.3320 - val_accuracy: 0.8700 - 520s/epoch - 3s/step\n",
      "Epoch 21/30\n",
      "160/160 - 520s - loss: 0.2690 - accuracy: 0.8913 - val_loss: 0.3428 - val_accuracy: 0.8725 - 520s/epoch - 3s/step\n",
      "Epoch 22/30\n",
      "160/160 - 521s - loss: 0.2453 - accuracy: 0.9137 - val_loss: 0.3575 - val_accuracy: 0.8900 - 521s/epoch - 3s/step\n",
      "Epoch 23/30\n",
      "160/160 - 520s - loss: 0.2365 - accuracy: 0.9119 - val_loss: 0.3560 - val_accuracy: 0.8900 - 520s/epoch - 3s/step\n",
      "Epoch 24/30\n",
      "160/160 - 519s - loss: 0.2159 - accuracy: 0.9231 - val_loss: 0.4870 - val_accuracy: 0.8275 - 519s/epoch - 3s/step\n",
      "Epoch 25/30\n",
      "160/160 - 518s - loss: 0.2341 - accuracy: 0.9119 - val_loss: 0.3363 - val_accuracy: 0.8800 - 518s/epoch - 3s/step\n",
      "Epoch 26/30\n",
      "160/160 - 517s - loss: 0.2299 - accuracy: 0.9187 - val_loss: 0.3513 - val_accuracy: 0.8675 - 517s/epoch - 3s/step\n",
      "Epoch 27/30\n",
      "160/160 - 517s - loss: 0.2035 - accuracy: 0.9281 - val_loss: 0.3611 - val_accuracy: 0.8875 - 517s/epoch - 3s/step\n",
      "Epoch 28/30\n",
      "160/160 - 519s - loss: 0.2139 - accuracy: 0.9256 - val_loss: 0.3540 - val_accuracy: 0.8900 - 519s/epoch - 3s/step\n",
      "Epoch 29/30\n",
      "160/160 - 517s - loss: 0.2000 - accuracy: 0.9269 - val_loss: 0.3633 - val_accuracy: 0.8850 - 517s/epoch - 3s/step\n",
      "Epoch 30/30\n",
      "160/160 - 521s - loss: 0.2123 - accuracy: 0.9225 - val_loss: 0.3792 - val_accuracy: 0.8650 - 521s/epoch - 3s/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=30, validation_data=test_generator, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-11T14:02:30.183078Z",
     "iopub.status.idle": "2022-03-11T14:02:30.185057Z",
     "shell.execute_reply": "2022-03-11T14:02:30.184854Z",
     "shell.execute_reply.started": "2022-03-11T14:02:30.184829Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save perfomance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipynbname\n",
    "import json\n",
    "from keras.utils.layer_utils import count_params\n",
    "\n",
    "current_directory = os.getcwd() + '/'\n",
    "results_directory = current_directory.replace('memo_notebooks', 'memo_results')\n",
    "\n",
    "experiment_name = ipynbname.name()\n",
    "\n",
    "# Save history as json\n",
    "with open(results_directory + experiment_name + '.json', 'w') as f:\n",
    "    json.dump(history.history, f)\n",
    "    \n",
    "# Compute max val_accuracy and number of trainable params and append to stats\n",
    "max_val_acc = max(history.history['val_accuracy'])\n",
    "trainable_params = count_params(model.trainable_weights)\n",
    "\n",
    "# Store value in latex table format\n",
    "acc_string = f'{experiment_name} & {max_val_acc:.2%}'.replace('%', '\\%')\n",
    "acc_params_string = acc_string + f' & {trainable_params}'\n",
    "\n",
    "with open(results_directory + 'acc.dat', 'a') as f:\n",
    "    f.write(acc_string + ' \\\\\\ \\n')\n",
    "    \n",
    "with open(results_directory + 'acc_params.dat', 'a') as f:\n",
    "    f.write(acc_params_string + ' \\\\\\ \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg-info-env",
   "language": "python",
   "name": "tfg-info-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
